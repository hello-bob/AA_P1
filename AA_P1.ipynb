{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f115f2a3-38a9-4391-b240-33e8d9069276",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Your model will be evaluated using two metrics: profit @ top-20, and AUC. The reasons for this is to be in line with a more realistic setting. E.g. one can image data scientists in a team arguing to use AUC and optimize for that. However, as seen in the course, for this scenario, we also imagine management arguing that there is not enough budget (in terms of time and money) to contact a lot of people (or hand out a lot of promotions). Hence, they have come up with the following: based on the top-k would-be churners as predicted by your model, sum some proxy of \"retained profitability\" in case the customer was indeed a churner, or zero otherwise\n",
    "\n",
    "As a proxy of profitability, the feature average cost min was deemed to be a good value. Based on the size of the test set, k=20 was deemed to be a good choice. Hence, management cares about optimizing this metric\n",
    "Note that only about half of the test set is used for the \"public\" leaderboard. That means that the score you will see on the leaderboard is done using this part of the test only (you don't know which half). Later on through the semester, submissions are frozen and the resuls on the \"hidden\" part will be revealed\n",
    "\n",
    "Also, whilst you can definitely try, the goal is not to \"win\", but to help you reflect on your model's results, see how others are doing, etc.\n",
    "\n",
    "Objectives:\n",
    "\n",
    "Some groups prefer to write their final report using Jupyter Notebook, which is fine too, as long as it is readable top-to-bottom\n",
    "\n",
    "You can use any predictive technique/approach you want, though focus on the whole process: general setup, critical thinking, and the ability to get and validate an outcome\n",
    "\n",
    "You're free to use unsupervised technique for your data exploration part, too. When you decide to build a black box model, including some interpretability techniques to explain it is a plus\n",
    "\n",
    "Any other assumptions or insights are thoughts can be included as well: the idea is to take what we've seen in class, get your hands dirty and try out what we've seen\n",
    "\n",
    "Perform a critical review of the evaluation metric chosen by management. How in line is it with AUC? What would you have picked instead? Were there particular issues with this chosen metric, in your view?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f37fc-1746-44a5-aae7-235843420f05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27422043-f2b6-411a-9b7d-02a7a65c638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising\n",
    "TRAIN_SET_FRAC = 0.8\n",
    "SEED = 42\n",
    "TARGET_VAR = \"target\"\n",
    "DROP_VARS = ['Connect_Date', 'id'] # TBC\n",
    "KFOLD = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d296096",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHib urls to fetch data from\n",
    "url_train = 'https://raw.githubusercontent.com/hello-bob/AA_P1/main/data/train.csv'\n",
    "url_test = 'https://raw.githubusercontent.com/hello-bob/AA_P1/main/data/test.csv'\n",
    "\n",
    "# Read train and test data\n",
    "train_data = pd.read_csv(url_train, sep = ',', skipinitialspace = True, engine = 'python')\n",
    "train_data = train_data.drop(columns=DROP_VARS)\n",
    "test_data  = pd.read_csv(url_test, sep = ',', skipinitialspace = True, engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd79c8d",
   "metadata": {},
   "source": [
    "**Data exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4d189-2e25-4267-8bce-4ad4ca80f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3045da-ba51-4ded-97cc-e1205333526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic descriptives\n",
    "train_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571b1fd-3271-4143-9d46-7fa3a7e783f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing data before modelling: Can quantitate and put it on the report since 4/5k samples\n",
    "# Apply on the test set. Train set is ok.\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "train_data.isnull().any().sort_values(ascending=False) # Columns with missing values: Dropped_calls_ratio, Usage_Band, call_cost_per_min.\n",
    "train_data[train_data.isnull().any(axis=1)] # 4 cases, 2 churners\n",
    "\n",
    "imputer_compiled = ColumnTransformer(\n",
    "    [(\"numeric_imputer\", SimpleImputer(strategy=\"median\",), [\"Dropped_calls_ratio\", \"call_cost_per_min\"]),\n",
    "     (\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\"), [\"Usage_Band\"])]\n",
    ")\n",
    "\n",
    "# Imput median for numeric variables first. Because \"most_frequent\" strategy will impute for both numeric and categorical data\n",
    "train_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\", \"Usage_Band\"]] = imputer_compiled.fit_transform(train_data)\n",
    "test_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\", \"Usage_Band\"]] = imputer_compiled.transform(test_data)\n",
    "\n",
    "# Correcting dtype\n",
    "train_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]] = train_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]].astype(float)\n",
    "test_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]] = test_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca331e3-1828-47d3-95ef-54b2c13b6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [For report] Pie chart about class inbalance (train set) + Percentage churn in categorical variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [For report] correlation plot\n",
    "corr = train_data.corr(numeric_only=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x = corr.columns,\n",
    "        y = corr.index,\n",
    "        z = np.array(corr),\n",
    "        text=corr.values,\n",
    "        texttemplate='%{text:.2f}'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f38a9-01d7-49f8-a632-94777c042378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [For report] Correlation between categorical variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b062db3d",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values\n",
    "# outliers\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "outlier_df = (train_data.select_dtypes(include='number')\n",
    "              .drop(columns=TARGET_VAR)\n",
    "              .dropna()\n",
    "              .copy())\n",
    "\n",
    "iso_forest = IsolationForest(random_state=SEED, n_jobs=-1).fit(outlier_df)\n",
    "pred = iso_forest.predict(outlier_df)\n",
    "outlier_df['is_outlier'] = (pred == -1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bdac4-f928-42e8-934d-9543a194b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding what drives outliers: TBC\n",
    "corr = outlier_df.corr(numeric_only=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x = corr.columns,\n",
    "        y = corr.index,\n",
    "        z = np.array(corr),\n",
    "        text=corr.values,\n",
    "        texttemplate='%{text:.2f}'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48abfad-9887-401e-a387-bf1a43e10b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836b39b-91db-4b0e-9391-a092407db57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/404017/how-to-get-top-features-that-contribute-to-anomalies-in-isolation-forest\n",
    "import shap\n",
    "\n",
    "# Create shap values and plot them\n",
    "shap_values = shap.TreeExplainer(iso_forest).shap_values(outlier_df)\n",
    "shap.summary_plot(shap_values, outlier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c616c6-b069-4879-9fa9-ca5116e5ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide or not to keep/drop/use the outliers as a feature. To research on churn context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5916f9f-3460-4a12-8ac1-8b5cfe8392c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb48688-cd79-40a8-a170-4ffa022e2950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc6a394-39ae-44e0-be8a-c4e289fe5111",
   "metadata": {},
   "source": [
    "**Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c6f2d-0b28-40c0-88f9-8abcd84bf3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=TARGET_VAR)\n",
    "y = train_data[TARGET_VAR] \n",
    "\n",
    "NUM_VARS = train_data.select_dtypes(include='number').drop(columns=TARGET_VAR).columns\n",
    "CAT_VARS = train_data.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f56a44-d58a-4cb4-b9ff-f3a54d71bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Define preprocessors for numerical and categorical features\n",
    "numerical_preprocessor = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_preprocessor = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abc0a1-483f-42d5-a15f-679200a52eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessors and model\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", ColumnTransformer([\n",
    "        (\"numerical\", numerical_preprocessor, NUM_VARS),\n",
    "        (\"categorical\", categorical_preprocessor, CAT_VARS)\n",
    "    ])),\n",
    "    (\"model\", SVC(probability=True, random_state=SEED))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c74dbe-c4a1-4197-83b8-2e1a4607933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SVM\n",
    "parameters = {'model__kernel':['linear', 'rbf'], \n",
    "              'model__C':[1]} # rmb to add the double underscores to allow gridsearch to fit on pipelines\n",
    "svc_gs_est = GridSearchCV(estimator=model, param_grid=parameters,cv=KFOLD,\n",
    "                      scoring=\"roc_auc\",n_jobs=-1, refit=True)\n",
    "svc_gs_est.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4184d7c-0bf5-439f-8a0b-9f4ce5f775cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>param_model__kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.127157</td>\n",
       "      <td>0.602093</td>\n",
       "      <td>0.216811</td>\n",
       "      <td>0.060668</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'model__C': 1, 'model__kernel': 'rbf'}</td>\n",
       "      <td>0.936874</td>\n",
       "      <td>0.903418</td>\n",
       "      <td>0.909888</td>\n",
       "      <td>0.940346</td>\n",
       "      <td>0.905075</td>\n",
       "      <td>0.919120</td>\n",
       "      <td>0.016092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.448209</td>\n",
       "      <td>1.201936</td>\n",
       "      <td>0.043547</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'model__C': 1, 'model__kernel': 'linear'}</td>\n",
       "      <td>0.905346</td>\n",
       "      <td>0.908717</td>\n",
       "      <td>0.902435</td>\n",
       "      <td>0.911292</td>\n",
       "      <td>0.910740</td>\n",
       "      <td>0.907706</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       3.127157      0.602093         0.216811        0.060668   \n",
       "0       4.448209      1.201936         0.043547        0.007839   \n",
       "\n",
       "  param_model__C param_model__kernel  \\\n",
       "1              1                 rbf   \n",
       "0              1              linear   \n",
       "\n",
       "                                       params  split0_test_score  \\\n",
       "1     {'model__C': 1, 'model__kernel': 'rbf'}           0.936874   \n",
       "0  {'model__C': 1, 'model__kernel': 'linear'}           0.905346   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "1           0.903418           0.909888           0.940346           0.905075   \n",
       "0           0.908717           0.902435           0.911292           0.910740   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.919120        0.016092                1  \n",
       "0         0.907706        0.003360                2  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gs_results = pd.DataFrame(data=svc_gs_est.cv_results_)\n",
    "svc_gs_results.sort_values(by='rank_test_score', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3bd00-ce25-485d-972b-ebc36b5b7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef09650-f231-4b8e-bda4-b47eacce506b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffc532f4-06da-4a38-aafb-dd9a7f7b32d4",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b1c70-918e-4389-8e65-d30a3917ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain best model: Set up the params accordingly\n",
    "numerical_preprocessor = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_preprocessor = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n",
    "])\n",
    "\n",
    "best_model = Pipeline([\n",
    "    (\"preprocessor\", ColumnTransformer([\n",
    "        (\"numerical\", numerical_preprocessor, NUM_VARS),\n",
    "        (\"categorical\", categorical_preprocessor, CAT_VARS)\n",
    "    ])),\n",
    "    (\"model\", SVC(probability=True, random_state=SEED, C=1, kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "\n",
    "best_model.fit(X, y)\n",
    "pred = pd.DataFrame(best_model.predict_proba(test_data), \n",
    "                    columns=[\"0\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e38898-915b-46a7-8309-d62194e9bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For submission\n",
    "test_data_sub = pd.DataFrame(data={'ID':test_data['id'], \n",
    "                                   'PRED':pred[\"1\"]})\n",
    "test_data_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333172b",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41843607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, NUM_VARS),\n",
    "        (\"cat\", categorical_transformer, CAT_VARS),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "# Alternatively split train-test before, do preprocessing on training data (fit_transform) then transform test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4db406",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "test_size=0.2, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3dd2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e7e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11715cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "print(\"accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf216482",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"objective\":\"binary:logistic\",\"max_depth\":4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe117f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=4,\n",
    "num_boost_round=10, metrics=\"auc\", as_pandas=True, seed = 420)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUC: %f\" %((cv_results[\"test-auc-mean\"]).iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a025bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "gbm_param_grid = {'learning_rate': [0.01,0.1,0.5,0.9],\n",
    "                  'n_estimators': [50],\n",
    "                  'subsample': [0.3, 0.5, 0.9],\n",
    "                  'max_depth': [3, 4, 5, 10]}\n",
    "\n",
    "gbm = xgb.XGBClassifier()\n",
    "grid_auc = GridSearchCV(estimator=gbm,param_grid=gbm_param_grid,\n",
    "scoring='roc_auc', cv=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_auc.fit(X, y)\n",
    "print(\"Best parameters found: \",grid_auc.best_params_)\n",
    "print(\"Lowest AUC found: \", np.sqrt(np.abs(grid_auc.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7cb43d",
   "metadata": {},
   "source": [
    "Tuning individual parameters, using xgboost's built-in cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83d64b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    num_boosting_rounds       auc\n",
      "0                     5  0.887040\n",
      "1                    10  0.926403\n",
      "2                    15  0.931121\n",
      "3                    20  0.931976\n",
      "4                    21  0.931619\n",
      "5                    22  0.932006\n",
      "6                    23  0.932105\n",
      "7                    24  0.931427\n",
      "8                    25  0.931152\n",
      "9                    26  0.931289\n",
      "10                   27  0.931365\n",
      "11                   28  0.931454\n",
      "12                   29  0.930831\n",
      "13                   30  0.931385\n"
     ]
    }
   ],
   "source": [
    "# Tune boosting rounds: num_rounds\n",
    "params={\"objective\":\"binary:logistic\",\"max_depth\":4}\n",
    "num_rounds = [5, 10, 15, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
    "final_auc_per_round = []\n",
    "for curr_num_rounds in num_rounds:\n",
    "    cv_results = xgb.cv(  dtrain=churn_dmatrix\n",
    "                        , params=params\n",
    "                        , nfold=5\n",
    "                        , num_boost_round=curr_num_rounds\n",
    "                        , metrics=\"auc\"\n",
    "                        , as_pandas=True\n",
    "                        , seed=420\n",
    "                        )\n",
    "    final_auc_per_round.append(cv_results[\"test-auc-mean\"].tail().values[-1])\n",
    "\n",
    "num_rounds_aucs = list(zip(num_rounds, final_auc_per_round))\n",
    "print(pd.DataFrame(num_rounds_aucs, columns=[\"num_boosting_rounds\", \"auc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a109b18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0         0.843986       0.012999       0.834137      0.026721\n",
      "1         0.871512       0.004073       0.863295      0.013572\n",
      "2         0.875975       0.004784       0.866624      0.015697\n",
      "3         0.881229       0.006182       0.869440      0.013840\n",
      "4         0.899352       0.023111       0.887040      0.007989\n",
      "5         0.930135       0.004538       0.909397      0.014975\n",
      "6         0.937508       0.004778       0.918990      0.014786\n",
      "7         0.942165       0.004286       0.922538      0.016709\n",
      "8         0.947413       0.004621       0.923927      0.011666\n",
      "9         0.951834       0.004212       0.926403      0.012128\n",
      "10        0.954418       0.003076       0.928033      0.011876\n",
      "11        0.958006       0.004205       0.928746      0.013141\n",
      "12        0.960966       0.002897       0.929687      0.013613\n",
      "13        0.963332       0.003045       0.930444      0.014328\n",
      "14        0.965062       0.003191       0.931121      0.013706\n",
      "15        0.966896       0.003431       0.930893      0.014175\n",
      "16        0.968319       0.002498       0.931282      0.013791\n",
      "17        0.970063       0.002718       0.931732      0.013384\n",
      "18        0.971446       0.002652       0.931662      0.013627\n",
      "19        0.972970       0.002995       0.931976      0.013887\n",
      "20        0.974600       0.002145       0.931619      0.014251\n",
      "21        0.975344       0.002200       0.932006      0.014210\n",
      "22        0.976694       0.002062       0.932105      0.013424\n"
     ]
    }
   ],
   "source": [
    "# Automated boosting round selection using early stopping\n",
    "cv_results = xgb.cv(  dtrain=churn_dmatrix\n",
    "                    , params=params\n",
    "                    , nfold=5\n",
    "                    , num_boost_round=50\n",
    "                    , early_stopping_rounds=5\n",
    "                    , metrics=\"auc\"\n",
    "                    , as_pandas=True\n",
    "                    , seed=420\n",
    "                    )\n",
    "\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b188d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     eta  best_auc\n",
      "0  0.001  0.834137\n",
      "1  0.010  0.862392\n",
      "2  0.100  0.932728\n"
     ]
    }
   ],
   "source": [
    "# Tuning eta (learning rate)\n",
    "params={\"objective\":\"binary:logistic\",\"max_depth\":4}\n",
    "eta_vals = [0.001, 0.01, 0.1]\n",
    "best_auc = []\n",
    "\n",
    "for curr_val in eta_vals:\n",
    "    params[\"eta\"] = curr_val\n",
    "    cv_results = xgb.cv(  dtrain=churn_dmatrix\n",
    "                    , params=params\n",
    "                    , nfold=5\n",
    "                    , num_boost_round=50\n",
    "                    , early_stopping_rounds=5\n",
    "                    , metrics=\"auc\"\n",
    "                    , as_pandas=True\n",
    "                    , seed=420\n",
    "                    )\n",
    "    best_auc.append(cv_results[\"test-auc-mean\"].tail().values[-1])\n",
    "\n",
    "print(pd.DataFrame(list(zip(eta_vals, best_auc)), columns=[\"eta\", \"best_auc\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dffc172",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04bb3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_param_grid = {  'n_estimators': [10, 20, 30, 50]\n",
    "                  #, 'early_stopping_rounds': [5]\n",
    "                  , 'max_depth': range(2, 9)\n",
    "                  , 'learning_rate': [0.001, 0.01, 0.1]\n",
    "                  , 'subsample': [0.8, 1]\n",
    "                  , 'colsample_bytree': [0.2, 0.5, 0.8, 1]\n",
    "                  , 'reg_lambda': [0, 1, 5, 10]\n",
    "                  }\n",
    "\n",
    "gbm = xgb.XGBClassifier(random_state=420)\n",
    "grid_auc = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9aa8726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2688 candidates, totalling 13440 fits\n",
      "Best parameters found:  {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 50, 'reg_lambda': 0, 'subsample': 1}\n",
      "Lowest AUC found:  0.9430718366280477\n"
     ]
    }
   ],
   "source": [
    "grid_auc.fit(X, y)    # I think this fits it on the whole dataset, not just the 80% training. Also - validation? or it's inside cv?\n",
    "print(\"Best parameters found: \",grid_auc.best_params_)\n",
    "print(\"Lowest AUC found: \", grid_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5dfbdb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous code ran for 6.5+ minutes. Let's do RandomizedSearchCV, and get 1000 random models from the hyperparameter space\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "gbm_param_grid = {  'n_estimators': np.arange(5, 101, 1)\n",
    "                  , 'max_depth': range(2, 13)\n",
    "                  , 'learning_rate': np.arange(0.001, 5, 0.01)\n",
    "                  , 'subsample': [0.2, 0.4, 0.6, 0.8, 1]\n",
    "                  , 'colsample_bytree': [0.2, 0.5, 0.8, 1]\n",
    "                  , 'reg_lambda': [0, 1, 5, 10, 100]\n",
    "                  }\n",
    "\n",
    "gbm = xgb.XGBClassifier(random_state=420)\n",
    "randomized_auc = RandomizedSearchCV(estimator=gbm, param_distributions=gbm_param_grid, n_iter=1000, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ded0c408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "Best parameters found:  {'subsample': 0.8, 'reg_lambda': 0, 'n_estimators': 34, 'max_depth': 12, 'learning_rate': 0.08099999999999999, 'colsample_bytree': 1}\n",
      "Lowest AUC found:  0.9436782764340442\n"
     ]
    }
   ],
   "source": [
    "randomized_auc.fit(X, y)    # I think this fits it on the whole dataset, not just the 80% training. Also - validation? or it's inside cv?\n",
    "print(\"Best parameters found: \",randomized_auc.best_params_)\n",
    "print(\"Lowest AUC found: \", randomized_auc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44645aea",
   "metadata": {},
   "source": [
    "All in one - pipeline, xgboost with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c63b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_param_grid = {  'n_estimators': [10, 20]\n",
    "                  , 'max_depth': [10, 20]\n",
    "                  , 'learning_rate': [0.01, 0.1]\n",
    "                  , 'subsample': [0.8, 1]\n",
    "                  , 'colsample_bytree': [0.8, 1]\n",
    "                  , 'reg_lambda': [0, 1]\n",
    "                  }\n",
    "\n",
    "gbm = xgb.XGBClassifier(random_state=420)\n",
    "grid_auc = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b1de141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best parameters found:  {'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 10, 'reg_lambda': 0, 'subsample': 0.8}\n",
      "Lowest AUC found:  0.9441100727830973\n"
     ]
    }
   ],
   "source": [
    "grid_auc.fit(X, y)    # I think this fits it on the whole dataset, not just the 80% training. Also - validation? or it's inside cv?\n",
    "print(\"Best parameters found: \",grid_auc.best_params_)\n",
    "print(\"Lowest AUC found: \", grid_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48c66eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.432357</td>\n",
       "      <td>0.055280</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>0.010851</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 1, 'learning_rate': 0.1, ...</td>\n",
       "      <td>0.945158</td>\n",
       "      <td>0.941825</td>\n",
       "      <td>0.937982</td>\n",
       "      <td>0.957172</td>\n",
       "      <td>0.938414</td>\n",
       "      <td>0.944110</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.701782</td>\n",
       "      <td>0.037729</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 1, 'learning_rate': 0.1, ...</td>\n",
       "      <td>0.946496</td>\n",
       "      <td>0.933487</td>\n",
       "      <td>0.939336</td>\n",
       "      <td>0.954277</td>\n",
       "      <td>0.940633</td>\n",
       "      <td>0.942846</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.367997</td>\n",
       "      <td>0.019595</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 1, 'learning_rate': 0.01,...</td>\n",
       "      <td>0.948580</td>\n",
       "      <td>0.928324</td>\n",
       "      <td>0.936078</td>\n",
       "      <td>0.960504</td>\n",
       "      <td>0.939965</td>\n",
       "      <td>0.942690</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.636467</td>\n",
       "      <td>0.018652</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 1, 'learning_rate': 0.01,...</td>\n",
       "      <td>0.947733</td>\n",
       "      <td>0.926046</td>\n",
       "      <td>0.935262</td>\n",
       "      <td>0.961269</td>\n",
       "      <td>0.940652</td>\n",
       "      <td>0.942192</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.607997</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.1...</td>\n",
       "      <td>0.947979</td>\n",
       "      <td>0.930467</td>\n",
       "      <td>0.936351</td>\n",
       "      <td>0.953473</td>\n",
       "      <td>0.941125</td>\n",
       "      <td>0.941879</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.703184</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 1, 'learning_rate': 0.01,...</td>\n",
       "      <td>0.927162</td>\n",
       "      <td>0.918710</td>\n",
       "      <td>0.921301</td>\n",
       "      <td>0.937759</td>\n",
       "      <td>0.920596</td>\n",
       "      <td>0.925106</td>\n",
       "      <td>0.006929</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.384969</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 1, 'learning_rate': 0.01,...</td>\n",
       "      <td>0.922604</td>\n",
       "      <td>0.917949</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>0.939231</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>0.922941</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.356656</td>\n",
       "      <td>0.030918</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 1, 'learning_rate': 0.01,...</td>\n",
       "      <td>0.919845</td>\n",
       "      <td>0.911476</td>\n",
       "      <td>0.912763</td>\n",
       "      <td>0.938349</td>\n",
       "      <td>0.921537</td>\n",
       "      <td>0.920794</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2.544092</td>\n",
       "      <td>0.342451</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 1, 'learning_rate': 0.01,...</td>\n",
       "      <td>0.937346</td>\n",
       "      <td>0.897511</td>\n",
       "      <td>0.921601</td>\n",
       "      <td>0.927821</td>\n",
       "      <td>0.912201</td>\n",
       "      <td>0.919296</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.427574</td>\n",
       "      <td>0.232531</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 1, 'learning_rate': 0.01,...</td>\n",
       "      <td>0.929507</td>\n",
       "      <td>0.899438</td>\n",
       "      <td>0.920493</td>\n",
       "      <td>0.926549</td>\n",
       "      <td>0.912939</td>\n",
       "      <td>0.917785</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "48       0.432357      0.055280         0.011198        0.010851   \n",
       "52       0.701782      0.037729         0.007999        0.000004   \n",
       "32       0.367997      0.019595         0.004799        0.003918   \n",
       "36       0.636467      0.018652         0.006398        0.003199   \n",
       "20       0.607997      0.011310         0.006395        0.003197   \n",
       "..            ...           ...              ...             ...   \n",
       "37       0.703184      0.016702         0.008000        0.000005   \n",
       "33       0.384969      0.011756         0.004801        0.003920   \n",
       "43       0.356656      0.030918         0.004800        0.003919   \n",
       "45       2.544092      0.342451         0.006406        0.003203   \n",
       "41       1.427574      0.232531         0.008003        0.000002   \n",
       "\n",
       "   param_colsample_bytree param_learning_rate param_max_depth  \\\n",
       "48                      1                 0.1              10   \n",
       "52                      1                 0.1              10   \n",
       "32                      1                0.01              10   \n",
       "36                      1                0.01              10   \n",
       "20                    0.8                 0.1              10   \n",
       "..                    ...                 ...             ...   \n",
       "37                      1                0.01              10   \n",
       "33                      1                0.01              10   \n",
       "43                      1                0.01              20   \n",
       "45                      1                0.01              20   \n",
       "41                      1                0.01              20   \n",
       "\n",
       "   param_n_estimators param_reg_lambda param_subsample  \\\n",
       "48                 10                0             0.8   \n",
       "52                 20                0             0.8   \n",
       "32                 10                0             0.8   \n",
       "36                 20                0             0.8   \n",
       "20                 20                0             0.8   \n",
       "..                ...              ...             ...   \n",
       "37                 20                0               1   \n",
       "33                 10                0               1   \n",
       "43                 10                1               1   \n",
       "45                 20                0               1   \n",
       "41                 10                0               1   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "48  {'colsample_bytree': 1, 'learning_rate': 0.1, ...           0.945158   \n",
       "52  {'colsample_bytree': 1, 'learning_rate': 0.1, ...           0.946496   \n",
       "32  {'colsample_bytree': 1, 'learning_rate': 0.01,...           0.948580   \n",
       "36  {'colsample_bytree': 1, 'learning_rate': 0.01,...           0.947733   \n",
       "20  {'colsample_bytree': 0.8, 'learning_rate': 0.1...           0.947979   \n",
       "..                                                ...                ...   \n",
       "37  {'colsample_bytree': 1, 'learning_rate': 0.01,...           0.927162   \n",
       "33  {'colsample_bytree': 1, 'learning_rate': 0.01,...           0.922604   \n",
       "43  {'colsample_bytree': 1, 'learning_rate': 0.01,...           0.919845   \n",
       "45  {'colsample_bytree': 1, 'learning_rate': 0.01,...           0.937346   \n",
       "41  {'colsample_bytree': 1, 'learning_rate': 0.01,...           0.929507   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "48           0.941825           0.937982           0.957172   \n",
       "52           0.933487           0.939336           0.954277   \n",
       "32           0.928324           0.936078           0.960504   \n",
       "36           0.926046           0.935262           0.961269   \n",
       "20           0.930467           0.936351           0.953473   \n",
       "..                ...                ...                ...   \n",
       "37           0.918710           0.921301           0.937759   \n",
       "33           0.917949           0.921625           0.939231   \n",
       "43           0.911476           0.912763           0.938349   \n",
       "45           0.897511           0.921601           0.927821   \n",
       "41           0.899438           0.920493           0.926549   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "48           0.938414         0.944110        0.007028                1  \n",
       "52           0.940633         0.942846        0.007054                2  \n",
       "32           0.939965         0.942690        0.011041                3  \n",
       "36           0.940652         0.942192        0.011880                4  \n",
       "20           0.941125         0.941879        0.008161                5  \n",
       "..                ...              ...             ...              ...  \n",
       "37           0.920596         0.925106        0.006929               60  \n",
       "33           0.913295         0.922941        0.008777               61  \n",
       "43           0.921537         0.920794        0.009601               62  \n",
       "45           0.912201         0.919296        0.013629               63  \n",
       "41           0.912939         0.917785        0.010785               64  \n",
       "\n",
       "[64 rows x 19 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_auc_results = pd.DataFrame(data=grid_auc.cv_results_)\n",
    "grid_auc_results.sort_values(by='rank_test_score', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10cffb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_param_grid = {  'n_estimators': [10, 20]\n",
    "                  , 'max_depth': [10, 20]\n",
    "                  , 'learning_rate': [0.01, 0.1]\n",
    "                  , 'subsample': [0.8, 1]\n",
    "                  , 'colsample_bytree': [0.8, 1]\n",
    "                  , 'reg_lambda': [0, 1]\n",
    "                  }\n",
    "\n",
    "gbm = xgb.XGBClassifier(random_state=420)\n",
    "randomized_auc = RandomizedSearchCV(estimator=gbm, param_distributions=gbm_param_grid, n_iter=10, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ae36840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters found:  {'subsample': 0.8, 'reg_lambda': 0, 'n_estimators': 20, 'max_depth': 10, 'learning_rate': 0.01, 'colsample_bytree': 1}\n",
      "Lowest AUC found:  0.9421923788972808\n"
     ]
    }
   ],
   "source": [
    "randomized_auc.fit(X, y)    # I think this fits it on the whole dataset, not just the 80% training. Also - validation? or it's inside cv?\n",
    "print(\"Best parameters found: \",randomized_auc.best_params_)\n",
    "print(\"Lowest AUC found: \", randomized_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed4a5b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.681047</td>\n",
       "      <td>0.027432</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'subsample': 0.8, 'reg_lambda': 0, 'n_estimat...</td>\n",
       "      <td>0.947733</td>\n",
       "      <td>0.926046</td>\n",
       "      <td>0.935262</td>\n",
       "      <td>0.961269</td>\n",
       "      <td>0.940652</td>\n",
       "      <td>0.942192</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.056358</td>\n",
       "      <td>0.080919</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 1, 'reg_lambda': 1, 'n_estimator...</td>\n",
       "      <td>0.951323</td>\n",
       "      <td>0.937877</td>\n",
       "      <td>0.933483</td>\n",
       "      <td>0.947924</td>\n",
       "      <td>0.929745</td>\n",
       "      <td>0.940070</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.199039</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 0.8, 'reg_lambda': 1, 'n_estimat...</td>\n",
       "      <td>0.952880</td>\n",
       "      <td>0.926853</td>\n",
       "      <td>0.940795</td>\n",
       "      <td>0.949848</td>\n",
       "      <td>0.923901</td>\n",
       "      <td>0.938855</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632894</td>\n",
       "      <td>0.027085</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'subsample': 0.8, 'reg_lambda': 1, 'n_estimat...</td>\n",
       "      <td>0.948369</td>\n",
       "      <td>0.934985</td>\n",
       "      <td>0.930568</td>\n",
       "      <td>0.949727</td>\n",
       "      <td>0.925069</td>\n",
       "      <td>0.937744</td>\n",
       "      <td>0.009760</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.374222</td>\n",
       "      <td>0.097859</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'subsample': 0.8, 'reg_lambda': 0, 'n_estimat...</td>\n",
       "      <td>0.945942</td>\n",
       "      <td>0.924403</td>\n",
       "      <td>0.936546</td>\n",
       "      <td>0.947487</td>\n",
       "      <td>0.931808</td>\n",
       "      <td>0.937237</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.440511</td>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 1, 'reg_lambda': 0, 'n_estimator...</td>\n",
       "      <td>0.949887</td>\n",
       "      <td>0.927228</td>\n",
       "      <td>0.935270</td>\n",
       "      <td>0.952845</td>\n",
       "      <td>0.920616</td>\n",
       "      <td>0.937169</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796079</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 1, 'reg_lambda': 1, 'n_estimator...</td>\n",
       "      <td>0.952907</td>\n",
       "      <td>0.931731</td>\n",
       "      <td>0.928925</td>\n",
       "      <td>0.943507</td>\n",
       "      <td>0.924991</td>\n",
       "      <td>0.936412</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.319031</td>\n",
       "      <td>0.159208</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 1, 'reg_lambda': 0, 'n_estimator...</td>\n",
       "      <td>0.949259</td>\n",
       "      <td>0.928976</td>\n",
       "      <td>0.926885</td>\n",
       "      <td>0.945969</td>\n",
       "      <td>0.928311</td>\n",
       "      <td>0.935880</td>\n",
       "      <td>0.009661</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.441069</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'subsample': 0.8, 'reg_lambda': 0, 'n_estimat...</td>\n",
       "      <td>0.940483</td>\n",
       "      <td>0.931899</td>\n",
       "      <td>0.935110</td>\n",
       "      <td>0.947487</td>\n",
       "      <td>0.922713</td>\n",
       "      <td>0.935538</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.773034</td>\n",
       "      <td>0.080382</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 1, 'reg_lambda': 0, 'n_estimator...</td>\n",
       "      <td>0.943726</td>\n",
       "      <td>0.923365</td>\n",
       "      <td>0.927130</td>\n",
       "      <td>0.933631</td>\n",
       "      <td>0.911623</td>\n",
       "      <td>0.927895</td>\n",
       "      <td>0.010672</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6       0.681047      0.027432         0.006397        0.003198   \n",
       "7       1.056358      0.080919         0.008000        0.000006   \n",
       "0       0.199039      0.011889         0.007999        0.000001   \n",
       "3       0.632894      0.027085         0.007995        0.000007   \n",
       "4       2.374222      0.097859         0.006397        0.003199   \n",
       "2       0.440511      0.021383         0.008106        0.000202   \n",
       "9       0.796079      0.065245         0.008460        0.000923   \n",
       "8       2.319031      0.159208         0.006926        0.003609   \n",
       "5       1.441069      0.033816         0.004801        0.003920   \n",
       "1       1.773034      0.080382         0.007998        0.005059   \n",
       "\n",
       "  param_subsample param_reg_lambda param_n_estimators param_max_depth  \\\n",
       "6             0.8                0                 20              10   \n",
       "7               1                1                 20              20   \n",
       "0             0.8                1                 10              10   \n",
       "3             0.8                1                 10              20   \n",
       "4             0.8                0                 20              20   \n",
       "2               1                0                 10              10   \n",
       "9               1                1                 20              20   \n",
       "8               1                0                 20              20   \n",
       "5             0.8                0                 10              20   \n",
       "1               1                0                 10              20   \n",
       "\n",
       "  param_learning_rate param_colsample_bytree  \\\n",
       "6                0.01                      1   \n",
       "7                 0.1                    0.8   \n",
       "0                0.01                    0.8   \n",
       "3                 0.1                      1   \n",
       "4                0.01                      1   \n",
       "2                0.01                    0.8   \n",
       "9                0.01                    0.8   \n",
       "8                 0.1                    0.8   \n",
       "5                0.01                      1   \n",
       "1                 0.1                    0.8   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "6  {'subsample': 0.8, 'reg_lambda': 0, 'n_estimat...           0.947733   \n",
       "7  {'subsample': 1, 'reg_lambda': 1, 'n_estimator...           0.951323   \n",
       "0  {'subsample': 0.8, 'reg_lambda': 1, 'n_estimat...           0.952880   \n",
       "3  {'subsample': 0.8, 'reg_lambda': 1, 'n_estimat...           0.948369   \n",
       "4  {'subsample': 0.8, 'reg_lambda': 0, 'n_estimat...           0.945942   \n",
       "2  {'subsample': 1, 'reg_lambda': 0, 'n_estimator...           0.949887   \n",
       "9  {'subsample': 1, 'reg_lambda': 1, 'n_estimator...           0.952907   \n",
       "8  {'subsample': 1, 'reg_lambda': 0, 'n_estimator...           0.949259   \n",
       "5  {'subsample': 0.8, 'reg_lambda': 0, 'n_estimat...           0.940483   \n",
       "1  {'subsample': 1, 'reg_lambda': 0, 'n_estimator...           0.943726   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "6           0.926046           0.935262           0.961269           0.940652   \n",
       "7           0.937877           0.933483           0.947924           0.929745   \n",
       "0           0.926853           0.940795           0.949848           0.923901   \n",
       "3           0.934985           0.930568           0.949727           0.925069   \n",
       "4           0.924403           0.936546           0.947487           0.931808   \n",
       "2           0.927228           0.935270           0.952845           0.920616   \n",
       "9           0.931731           0.928925           0.943507           0.924991   \n",
       "8           0.928976           0.926885           0.945969           0.928311   \n",
       "5           0.931899           0.935110           0.947487           0.922713   \n",
       "1           0.923365           0.927130           0.933631           0.911623   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "6         0.942192        0.011880                1  \n",
       "7         0.940070        0.008284                2  \n",
       "0         0.938855        0.011738                3  \n",
       "3         0.937744        0.009760                4  \n",
       "4         0.937237        0.008666                5  \n",
       "2         0.937169        0.012521                6  \n",
       "9         0.936412        0.010304                7  \n",
       "8         0.935880        0.009661                8  \n",
       "5         0.935538        0.008308                9  \n",
       "1         0.927895        0.010672               10  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_auc_results = pd.DataFrame(data=randomized_auc.cv_results_)\n",
    "randomized_auc_results.sort_values(by='rank_test_score', ascending = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
