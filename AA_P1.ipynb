{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f115f2a3-38a9-4391-b240-33e8d9069276",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Your model will be evaluated using two metrics: profit @ top-20, and AUC. The reasons for this is to be in line with a more realistic setting. E.g. one can image data scientists in a team arguing to use AUC and optimize for that. However, as seen in the course, for this scenario, we also imagine management arguing that there is not enough budget (in terms of time and money) to contact a lot of people (or hand out a lot of promotions). Hence, they have come up with the following: based on the top-k would-be churners as predicted by your model, sum some proxy of \"retained profitability\" in case the customer was indeed a churner, or zero otherwise\n",
    "\n",
    "As a proxy of profitability, the feature average cost min was deemed to be a good value. Based on the size of the test set, k=20 was deemed to be a good choice. Hence, management cares about optimizing this metric\n",
    "Note that only about half of the test set is used for the \"public\" leaderboard. That means that the score you will see on the leaderboard is done using this part of the test only (you don't know which half). Later on through the semester, submissions are frozen and the resuls on the \"hidden\" part will be revealed\n",
    "\n",
    "Also, whilst you can definitely try, the goal is not to \"win\", but to help you reflect on your model's results, see how others are doing, etc.\n",
    "\n",
    "Objectives:\n",
    "\n",
    "Some groups prefer to write their final report using Jupyter Notebook, which is fine too, as long as it is readable top-to-bottom\n",
    "\n",
    "You can use any predictive technique/approach you want, though focus on the whole process: general setup, critical thinking, and the ability to get and validate an outcome\n",
    "\n",
    "You're free to use unsupervised technique for your data exploration part, too. When you decide to build a black box model, including some interpretability techniques to explain it is a plus\n",
    "\n",
    "Any other assumptions or insights are thoughts can be included as well: the idea is to take what we've seen in class, get your hands dirty and try out what we've seen\n",
    "\n",
    "Perform a critical review of the evaluation metric chosen by management. How in line is it with AUC? What would you have picked instead? Were there particular issues with this chosen metric, in your view?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f37fc-1746-44a5-aae7-235843420f05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27422043-f2b6-411a-9b7d-02a7a65c638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising\n",
    "TRAIN_SET_FRAC = 0.8\n",
    "SEED = 42\n",
    "TARGET_VAR = \"target\"\n",
    "DROP_VARS = ['Connect_Date', 'id'] # TBC\n",
    "KFOLD = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d296096",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHib urls to fetch data from\n",
    "url_train = 'https://raw.githubusercontent.com/hello-bob/AA_P1/main/data/train.csv'\n",
    "url_test = 'https://raw.githubusercontent.com/hello-bob/AA_P1/main/data/test.csv'\n",
    "\n",
    "# Read train and test data\n",
    "train_data = pd.read_csv(url_train, sep = ',', skipinitialspace = True, engine = 'python')\n",
    "train_data = train_data.drop(columns=DROP_VARS)\n",
    "test_data  = pd.read_csv(url_test, sep = ',', skipinitialspace = True, engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd79c8d",
   "metadata": {},
   "source": [
    "**Data exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4d189-2e25-4267-8bce-4ad4ca80f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3045da-ba51-4ded-97cc-e1205333526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic descriptives\n",
    "train_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571b1fd-3271-4143-9d46-7fa3a7e783f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing data before modelling: Can quantitate and put it on the report since 4/5k samples\n",
    "# Apply on the test set. Train set is ok.\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "train_data.isnull().any().sort_values(ascending=False) # Columns with missing values: Dropped_calls_ratio, Usage_Band, call_cost_per_min.\n",
    "train_data[train_data.isnull().any(axis=1)] # 4 cases, 2 churners\n",
    "\n",
    "imputer_compiled = ColumnTransformer(\n",
    "    [(\"numeric_imputer\", SimpleImputer(strategy=\"median\",), [\"Dropped_calls_ratio\", \"call_cost_per_min\"]),\n",
    "     (\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\"), [\"Usage_Band\"])]\n",
    ")\n",
    "\n",
    "# Imput median for numeric variables first. Because \"most_frequent\" strategy will impute for both numeric and categorical data\n",
    "train_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\", \"Usage_Band\"]] = imputer_compiled.fit_transform(train_data)\n",
    "test_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\", \"Usage_Band\"]] = imputer_compiled.transform(test_data)\n",
    "\n",
    "# Correcting dtype\n",
    "train_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]] = train_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]].astype(float)\n",
    "test_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]] = test_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca331e3-1828-47d3-95ef-54b2c13b6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [For report] Pie chart about class inbalance (train set) + Percentage churn in categorical variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [For report] correlation plot\n",
    "corr = train_data.corr(numeric_only=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x = corr.columns,\n",
    "        y = corr.index,\n",
    "        z = np.array(corr),\n",
    "        text=corr.values,\n",
    "        texttemplate='%{text:.2f}'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f38a9-01d7-49f8-a632-94777c042378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [For report] Correlation between categorical variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b062db3d",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values\n",
    "# outliers\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "outlier_df = (train_data.select_dtypes(include='number')\n",
    "              .drop(columns=TARGET_VAR)\n",
    "              .dropna()\n",
    "              .copy())\n",
    "\n",
    "iso_forest = IsolationForest(random_state=SEED, n_jobs=-1).fit(outlier_df)\n",
    "pred = iso_forest.predict(outlier_df)\n",
    "outlier_df['is_outlier'] = (pred == -1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bdac4-f928-42e8-934d-9543a194b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding what drives outliers: TBC\n",
    "corr = outlier_df.corr(numeric_only=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x = corr.columns,\n",
    "        y = corr.index,\n",
    "        z = np.array(corr),\n",
    "        text=corr.values,\n",
    "        texttemplate='%{text:.2f}'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48abfad-9887-401e-a387-bf1a43e10b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836b39b-91db-4b0e-9391-a092407db57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/404017/how-to-get-top-features-that-contribute-to-anomalies-in-isolation-forest\n",
    "import shap\n",
    "\n",
    "# Create shap values and plot them\n",
    "shap_values = shap.TreeExplainer(iso_forest).shap_values(outlier_df)\n",
    "shap.summary_plot(shap_values, outlier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c616c6-b069-4879-9fa9-ca5116e5ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide or not to keep/drop/use the outliers as a feature. To research on churn context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5916f9f-3460-4a12-8ac1-8b5cfe8392c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb48688-cd79-40a8-a170-4ffa022e2950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc6a394-39ae-44e0-be8a-c4e289fe5111",
   "metadata": {},
   "source": [
    "**Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c6f2d-0b28-40c0-88f9-8abcd84bf3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=TARGET_VAR)\n",
    "y = train_data[TARGET_VAR] \n",
    "\n",
    "NUM_VARS = train_data.select_dtypes(include='number').drop(columns=TARGET_VAR).columns\n",
    "CAT_VARS = train_data.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f56a44-d58a-4cb4-b9ff-f3a54d71bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Define preprocessors for numerical and categorical features\n",
    "numerical_preprocessor = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_preprocessor = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abc0a1-483f-42d5-a15f-679200a52eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessors and model\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", ColumnTransformer([\n",
    "        (\"numerical\", numerical_preprocessor, NUM_VARS),\n",
    "        (\"categorical\", categorical_preprocessor, CAT_VARS)\n",
    "    ])),\n",
    "    (\"model\", SVC(probability=True, random_state=SEED))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c74dbe-c4a1-4197-83b8-2e1a4607933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SVM\n",
    "parameters = {'model__kernel':['linear', 'rbf'], \n",
    "              'model__C':[1]} # rmb to add the double underscores to allow gridsearch to fit on pipelines\n",
    "svc_gs_est = GridSearchCV(estimator=model, param_grid=parameters,cv=KFOLD,\n",
    "                      scoring=\"roc_auc\",n_jobs=-1, refit=True)\n",
    "svc_gs_est.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4184d7c-0bf5-439f-8a0b-9f4ce5f775cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gs_results = pd.DataFrame(data=svc_gs_est.cv_results_)\n",
    "svc_gs_results.sort_values(by='rank_test_score', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3bd00-ce25-485d-972b-ebc36b5b7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef09650-f231-4b8e-bda4-b47eacce506b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffc532f4-06da-4a38-aafb-dd9a7f7b32d4",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b1c70-918e-4389-8e65-d30a3917ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain best model: Set up the params accordingly\n",
    "numerical_preprocessor = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_preprocessor = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n",
    "])\n",
    "\n",
    "best_model = Pipeline([\n",
    "    (\"preprocessor\", ColumnTransformer([\n",
    "        (\"numerical\", numerical_preprocessor, NUM_VARS),\n",
    "        (\"categorical\", categorical_preprocessor, CAT_VARS)\n",
    "    ])),\n",
    "    (\"model\", SVC(probability=True, random_state=SEED, C=1, kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "\n",
    "best_model.fit(X, y)\n",
    "pred = pd.DataFrame(best_model.predict_proba(test_data), \n",
    "                    columns=[\"0\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e38898-915b-46a7-8309-d62194e9bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For submission\n",
    "test_data_sub = pd.DataFrame(data={'ID':test_data['id'], \n",
    "                                   'PRED':pred[\"1\"]})\n",
    "test_data_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333172b",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41843607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, NUM_VARS),\n",
    "        (\"cat\", categorical_transformer, CAT_VARS),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "# Alternatively split train-test before, do preprocessing on training data (fit_transform) then transform test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4db406",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y,\n",
    "test_size=0.2, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3dd2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e7e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11715cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
    "print(\"accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf216482",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"objective\":\"binary:logistic\",\"max_depth\":4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe117f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=4,\n",
    "num_boost_round=10, metrics=\"auc\", as_pandas=True, seed = 420)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUC: %f\" %((cv_results[\"test-auc-mean\"]).iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a025bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "gbm_param_grid = {'learning_rate': [0.01,0.1,0.5,0.9],\n",
    "                  'n_estimators': [50],\n",
    "                  'subsample': [0.3, 0.5, 0.9]}\n",
    "\n",
    "gbm = xgb.XGBClassifier()\n",
    "grid_auc = GridSearchCV(estimator=gbm,param_grid=gbm_param_grid,\n",
    "scoring='roc_auc', cv=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e84e6c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "Best parameters found:  {'eta': 0.1, 'n_estimators': 50, 'subsample': 0.9}\n",
      "Lowest AUC found:  0.9691073591383579\n"
     ]
    }
   ],
   "source": [
    "grid_auc.fit(X, y)\n",
    "print(\"Best parameters found: \",grid_auc.best_params_)\n",
    "print(\"Lowest AUC found: \", np.sqrt(np.abs(grid_auc.best_score_)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
