{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f115f2a3-38a9-4391-b240-33e8d9069276",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Your model will be evaluated using two metrics: profit @ top-20, and AUC. The reasons for this is to be in line with a more realistic setting. E.g. one can image data scientists in a team arguing to use AUC and optimize for that. However, as seen in the course, for this scenario, we also imagine management arguing that there is not enough budget (in terms of time and money) to contact a lot of people (or hand out a lot of promotions). Hence, they have come up with the following: based on the top-k would-be churners as predicted by your model, sum some proxy of \"retained profitability\" in case the customer was indeed a churner, or zero otherwise\n",
    "\n",
    "As a proxy of profitability, the feature average cost min was deemed to be a good value. Based on the size of the test set, k=20 was deemed to be a good choice. Hence, management cares about optimizing this metric\n",
    "Note that only about half of the test set is used for the \"public\" leaderboard. That means that the score you will see on the leaderboard is done using this part of the test only (you don't know which half). Later on through the semester, submissions are frozen and the resuls on the \"hidden\" part will be revealed\n",
    "\n",
    "Also, whilst you can definitely try, the goal is not to \"win\", but to help you reflect on your model's results, see how others are doing, etc.\n",
    "\n",
    "Objectives:\n",
    "\n",
    "Some groups prefer to write their final report using Jupyter Notebook, which is fine too, as long as it is readable top-to-bottom\n",
    "\n",
    "You can use any predictive technique/approach you want, though focus on the whole process: general setup, critical thinking, and the ability to get and validate an outcome\n",
    "\n",
    "You're free to use unsupervised technique for your data exploration part, too. When you decide to build a black box model, including some interpretability techniques to explain it is a plus\n",
    "\n",
    "Any other assumptions or insights are thoughts can be included as well: the idea is to take what we've seen in class, get your hands dirty and try out what we've seen\n",
    "\n",
    "Perform a critical review of the evaluation metric chosen by management. How in line is it with AUC? What would you have picked instead? Were there particular issues with this chosen metric, in your view?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e826ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f37fc-1746-44a5-aae7-235843420f05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27422043-f2b6-411a-9b7d-02a7a65c638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising\n",
    "TRAIN_SET_FRAC = 0.8\n",
    "SEED = 42\n",
    "TARGET_VAR = \"target\"\n",
    "DROP_VARS = ['Connect_Date', 'id'] # TBC\n",
    "KFOLD = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d296096",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHib urls to fetch data from\n",
    "url_train = 'https://raw.githubusercontent.com/hello-bob/AA_P1/main/data/train.csv'\n",
    "url_test = 'https://raw.githubusercontent.com/hello-bob/AA_P1/main/data/test.csv'\n",
    "\n",
    "# Read train and test data\n",
    "train_data = pd.read_csv(url_train, sep = ',', skipinitialspace = True, engine = 'python')\n",
    "train_data = train_data.drop(columns=DROP_VARS)\n",
    "test_data  = pd.read_csv(url_test, sep = ',', skipinitialspace = True, engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd79c8d",
   "metadata": {},
   "source": [
    "**Data exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4d189-2e25-4267-8bce-4ad4ca80f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3045da-ba51-4ded-97cc-e1205333526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic descriptives\n",
    "train_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da0657-d11f-4ce3-b36f-d493633faea2",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571b1fd-3271-4143-9d46-7fa3a7e783f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing data before modelling: Can quantitate and put it on the report since 4/5k samples\n",
    "# Apply on the test set. Train set is ok.\n",
    "\n",
    "train_data.isnull().any().sort_values(ascending=False) # Columns with missing values: Dropped_calls_ratio, Usage_Band, call_cost_per_min.\n",
    "train_data[train_data.isnull().any(axis=1)] # 4 cases, 2 churners\n",
    "\n",
    "imputer_compiled = ColumnTransformer(\n",
    "    [(\"numeric_imputer\", SimpleImputer(strategy=\"median\",), [\"Dropped_calls_ratio\", \"call_cost_per_min\"]),\n",
    "     (\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\"), [\"Usage_Band\"])]\n",
    ")\n",
    "\n",
    "# Imput median for numeric variables first. Because \"most_frequent\" strategy will impute for both numeric and categorical data\n",
    "train_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\", \"Usage_Band\"]] = imputer_compiled.fit_transform(train_data)\n",
    "test_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\", \"Usage_Band\"]] = imputer_compiled.transform(test_data)\n",
    "\n",
    "# Correcting dtype\n",
    "train_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]] = train_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]].astype(float)\n",
    "test_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]] = test_data[[\"Dropped_calls_ratio\", \"call_cost_per_min\"]].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1ac68-9bbd-4282-90b8-89d9e7451442",
   "metadata": {},
   "source": [
    "**Exploratory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca331e3-1828-47d3-95ef-54b2c13b6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [For report] Pie chart about class inbalance (train set) + Percentage churn in categorical variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3fd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [For report] correlation plot\n",
    "corr = train_data.corr(numeric_only=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x = corr.columns,\n",
    "        y = corr.index,\n",
    "        z = np.array(corr),\n",
    "        text=corr.values,\n",
    "        texttemplate='%{text:.2f}'\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26586a96-35e3-4e1e-a139-8d8053c3bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print correlations which has >0.7\n",
    "\"\"\"\n",
    "All_calls_mins highly correlated to National minutes. It's a sum of National minutes + International mins maybe. This may indicate that\n",
    "majority of calls are within nation. This corresponds to how Nat_call_cost_Sum is highly correlated to actual call cost. Not sure what's the\n",
    "diff betwen actuall call cost and total call cost. Nat_call_cost_Sum could be an adjustment of actual call cost, correlation 0.999.\n",
    "\n",
    "Total_call_cost most strongly correlated with International_mins_Sum and Total_Cost. This may suggest that costs are largely driven by \n",
    "international calls\n",
    "\n",
    "Not sure what total calls indicate, maybe it's cost from other telco-related services e.g. broadband, cable tv etc.\n",
    "\n",
    "Peak_mins_Sum highly correlated with all_calls_mins and national mins. This may make sense since the more minutes of calling, the higher\n",
    "likelihood of calling during the peak period?\n",
    "\n",
    "\"\"\"\n",
    "corr_long = train_data.corr(numeric_only=True).melt(ignore_index=False).reset_index(drop=False)\n",
    "corr_long = corr_long[(corr_long['index'] != corr_long['variable']) & (abs(corr_long['value']) >0.7)]\n",
    "corr_long.sort_values(by=['index', 'variable'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f40c4-a056-4419-a83a-bf703705d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(round((train_data['International_mins_Sum'] + train_data['National mins']),2) == round(train_data['All_calls_mins'], 2)).sum() #almost all\n",
    "train_data[['All_calls_mins', 'National mins']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72945191-8232-4df0-8622-4aebdc45b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f38a9-01d7-49f8-a632-94777c042378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [For report] Correlation between categorical variables, using cramer's V\n",
    "# Generally, \n",
    "from scipy.stats.contingency import association\n",
    "\n",
    "cat_corr_cols = train_data.select_dtypes('object').columns.to_list()\n",
    "while len(cat_corr_cols) > 0:\n",
    "    col = cat_corr_cols.pop(0)\n",
    "    print(f'Correlation for {col}')\n",
    "    for other_col in cat_corr_cols:\n",
    "        contingency_tbl = pd.crosstab(train_data[col], train_data[other_col])\n",
    "        cramer_V = association(contingency_tbl, method=\"cramer\")\n",
    "        print(f'Association with {other_col}: {cramer_V}')\n",
    "    print('\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a23673c-392c-4d38-8155-8aaef96af080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train_data['tariff'], train_data['Usage_Band'])\n",
    "pd.crosstab(train_data['Gender'], train_data['Handset'])\n",
    "pd.crosstab(train_data['high Dropped calls'], train_data['Handset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f838843-72c5-42f5-bb50-956761647903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the metric by management\n",
    "train_data.sort_values(by='average cost min', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e7b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying outliers via isolation forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "outlier_df = (train_data.select_dtypes(include='number')\n",
    "              .drop(columns=TARGET_VAR)\n",
    "              .dropna()\n",
    "              .copy())\n",
    "\n",
    "iso_forest = IsolationForest(random_state=SEED, n_jobs=-1, contamination=0.05).fit(outlier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ae922",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df['outlier_score'] = iso_forest.decision_function(outlier_df) # more negative indicates higher outlier-ness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836b39b-91db-4b0e-9391-a092407db57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/404017/how-to-get-top-features-that-contribute-to-anomalies-in-isolation-forest\n",
    "\"\"\"\n",
    "Outstanding variables contributing to outlier (to the left of 0 on x axis) are AveOffPeak, average cost min, AveWeekend, AveNational and \n",
    "Dropped_calls_ratio. These tend to indicate the higher the values, the more of an outlier they are.\n",
    "\"\"\"\n",
    "\n",
    "# Create shap values and plot them\n",
    "shap_values = shap.TreeExplainer(iso_forest).shap_values(outlier_df)\n",
    "shap.summary_plot(shap_values, outlier_df, plot_type='violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3969e6e-3415-40aa-9727-4b6fbb5577db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average shap per variable Top few: Weekend_calls_sum, nat_call_cost_sum, dropped_calls, average cost min\n",
    "# a global measure of feature importance (https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html)\n",
    "# These values seem low to the values I saw online. \n",
    "explainer = shap.Explainer(iso_forest, outlier_df)\n",
    "shap_values = explainer(outlier_df)\n",
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a7f3c-d87e-4042-a0dc-e97f6c9c2cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 of the top 10 outliers are churners. No discernible pattern between churn and non-churn. Propose to keep all and compare \n",
    "# between models which are robust against outliers, and those not.\n",
    "outlier_df[TARGET_VAR] = train_data[TARGET_VAR].copy()\n",
    "outlier_df.sort_values(by='outlier_score', ascending=True).head(10).sort_values(by='target')\n",
    "outlier_df.groupby('target').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc6a394-39ae-44e0-be8a-c4e289fe5111",
   "metadata": {},
   "source": [
    "**Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c6f2d-0b28-40c0-88f9-8abcd84bf3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=TARGET_VAR)\n",
    "y = train_data[TARGET_VAR] \n",
    "\n",
    "NUM_VARS = train_data.select_dtypes(include='number').drop(columns=TARGET_VAR).columns\n",
    "CAT_VARS = train_data.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60157d-b88a-48b7-ae93-592646fac04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NUM_VARS)\n",
    "print(CAT_VARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f56a44-d58a-4cb4-b9ff-f3a54d71bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessors for numerical and categorical features\n",
    "numerical_preprocessor = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_preprocessor = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abc0a1-483f-42d5-a15f-679200a52eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessors and model\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", ColumnTransformer([\n",
    "        (\"numerical\", numerical_preprocessor, NUM_VARS),\n",
    "        (\"categorical\", categorical_preprocessor, CAT_VARS)\n",
    "    ])),\n",
    "    (\"model\", SVC(probability=False, random_state=SEED, max_iter=10000))\n",
    "])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c74dbe-c4a1-4197-83b8-2e1a4607933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SVM\n",
    "parameters = {'model__kernel':['linear', 'rbf', 'sigmoid', 'poly'], \n",
    "              'model__C':[0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "              'model__gamma':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "             'model__class_weight':[None, 'balanced'],\n",
    "             'model__degree':[3,4,5]} # rmb to add the double underscores to allow gridsearch to fit on pipelines\n",
    "svc_gs_est = GridSearchCV(estimator=model, param_grid=parameters,cv=KFOLD,\n",
    "                      scoring=\"roc_auc\",n_jobs=-1, refit=False, verbose=10)\n",
    "svc_gs_est.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400731c-b836-42a0-87ae-9ba1acf49860",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gs_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4184d7c-0bf5-439f-8a0b-9f4ce5f775cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gs_results = pd.DataFrame(data=svc_gs_est.cv_results_)\n",
    "svc_gs_results.sort_values(by='rank_test_score', ascending = True).to_csv('output/svc_gridsearchcv.csv')\n",
    "svc_gs_results.sort_values(by='rank_test_score', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf85310-6664-49e2-ade5-21e2e21765b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params\n",
    "svc_gs_est.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b1c70-918e-4389-8e65-d30a3917ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain best model: Set up the params accordingly\n",
    "numerical_preprocessor = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_preprocessor = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n",
    "])\n",
    "\n",
    "best_svc_model = Pipeline([\n",
    "    (\"preprocessor\", ColumnTransformer([\n",
    "        (\"numerical\", numerical_preprocessor, NUM_VARS),\n",
    "        (\"categorical\", categorical_preprocessor, CAT_VARS)\n",
    "    ])),\n",
    "    (\"model\", SVC(probability=False, random_state=SEED, C=100, class_weight='balanced', kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "\n",
    "best_svc_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e38898-915b-46a7-8309-d62194e9bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For submission\n",
    "test_data_sub = pd.DataFrame(data={'ID':test_data['id'], \n",
    "                                   'PRED':best_model.predict(test_data)})\n",
    "test_data_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333172b",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ed4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41843607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "numeric_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, NUM_VARS),\n",
    "        (\"cat\", categorical_transformer, CAT_VARS)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "# Alternatively split train-test before, do preprocessing on training data (fit_transform) then transform test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X_preprocessed, y, test_size=0.2, stratify=y, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dffc172",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad460f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte class ratio. Will be used to assess class imbalance during training\n",
    "ratio = float(y_train.value_counts()[0]) / y_train.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfbdb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First do a random search over a large hyperparameter space, trying 1000 random models \n",
    "gbm_param_grid_large = {  'n_estimators': np.arange(5, 101, 1)\n",
    "                        , 'max_depth': range(2, 13)\n",
    "                        , 'learning_rate': np.arange(0.001, 5, 0.01)\n",
    "                        , 'subsample': [0.2, 0.4, 0.6, 0.8, 1]\n",
    "                        , 'colsample_bytree': [0.2, 0.5, 0.8, 1]\n",
    "                        , 'reg_lambda': [0, 1, 5, 10, 100]\n",
    "                        }\n",
    "\n",
    "gbm = xgb.XGBClassifier(random_state=420, scale_pos_weight=ratio)\n",
    "randomized_auc = RandomizedSearchCV(  estimator=gbm\n",
    "                                    , param_distributions=gbm_param_grid_large\n",
    "                                    , n_iter=1000\n",
    "                                    , scoring='roc_auc'\n",
    "                                    , cv=5\n",
    "                                    , n_jobs=-1\n",
    "                                    , verbose=1\n",
    "                                    , random_state=420)\n",
    "\n",
    "# See how the cross-validation performed (on the \"training\" data) and the best tuned hyperparameter values\n",
    "randomized_auc.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \",randomized_auc.best_params_)\n",
    "print(\"Lowest AUC found: \", randomized_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do another random search over a smaller hyperparameter space around the preivously found \"best\" values\n",
    "gbm_param_grid_medium = {  'n_estimators': np.arange(50, 120, 1)\n",
    "                         , 'max_depth': range(6, 15)\n",
    "                         , 'learning_rate': np.arange(0.001, 5, 0.01)\n",
    "                         , 'subsample': [0.6, 0.8, 1]\n",
    "                         , 'colsample_bytree': [0.8, 1]\n",
    "                         , 'reg_lambda': [0, 1, 2, 5]\n",
    "                         }\n",
    "\n",
    "gbm = xgb.XGBClassifier(random_state=420, scale_pos_weight=ratio)\n",
    "randomized_auc = RandomizedSearchCV(  estimator=gbm\n",
    "                                    , param_distributions=gbm_param_grid_medium\n",
    "                                    , n_iter=1000\n",
    "                                    , scoring='roc_auc'\n",
    "                                    , cv=5\n",
    "                                    , n_jobs=-1\n",
    "                                    , verbose=1\n",
    "                                    , random_state=420)\n",
    "\n",
    "# See how the cross-validation performed (on the \"training\" data) and the best tuned hyperparameter values\n",
    "randomized_auc.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \",randomized_auc.best_params_)\n",
    "print(\"Lowest AUC found: \", randomized_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got quite different reults, but different hyperparameter combinations can give similar results.\n",
    "# Finally a grid-search that is not random around the previous \"best\" values.\n",
    "gbm_param_grid = {  'n_estimators': [70, 80, 100, 120]\n",
    "                  , 'max_depth': [8, 10, 12]\n",
    "                  , 'learning_rate': [0.05, 0.1, 0.15, 0.2]\n",
    "                  , 'subsample': [0.8, 1]\n",
    "                  , 'colsample_bytree': [0.8, 1]\n",
    "                  , 'reg_lambda': [0, 1, 2]\n",
    "                  }\n",
    "\n",
    "gbm = xgb.XGBClassifier(random_state=420, scale_pos_weight=ratio)\n",
    "grid_auc = GridSearchCV(  estimator=gbm\n",
    "                        , param_grid=gbm_param_grid\n",
    "                        , scoring='roc_auc'\n",
    "                        , cv=5\n",
    "                        , n_jobs=-1\n",
    "                        , verbose=1\n",
    "                        )\n",
    "\n",
    "# See how the cross-validation performed (on the \"training\" data) and the best tuned hyperparameter values\n",
    "grid_auc.fit(X_train, y_train)\n",
    "print(\"Best parameters found: \", grid_auc.best_params_)\n",
    "print(\"Lowest AUC found: \", grid_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679bd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save an output based on the previous (last) grid search\n",
    "pd.DataFrame(grid_auc.cv_results_).sort_values(by='rank_test_score', ascending = True).to_csv('output/xgb_gridsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an idea about how the model performs on the test set\n",
    "# Test AUC is close to the \"best\" model AUC on the cross-validated training set which is a good indication of not suffering from overfitting\n",
    "predicted_probabilities = grid_auc.predict_proba(X_test)\n",
    "auc_score = roc_auc_score(y_test, predicted_probabilities[:, 1])\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3693840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train the tuned model on the entire training data (not just on the 80% of it)\n",
    "best_model_xgb = Pipeline([\n",
    "    (\"preprocessor\", ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, NUM_VARS),\n",
    "            (\"cat\", categorical_transformer, CAT_VARS)\n",
    "            ]\n",
    "    )),\n",
    "    (\"xgboost model\", grid_auc.best_estimator_)\n",
    "])\n",
    "\n",
    "\n",
    "best_model_xgb.fit(X, y)\n",
    "pred_xgb = pd.DataFrame(best_model_xgb.predict_proba(test_data), columns=[\"0\", \"1\"])\n",
    "\n",
    "# Creating data for submission\n",
    "test_data_sub = pd.DataFrame(data={'ID':test_data['id'], \n",
    "                                   'PRED':pred_xgb[\"1\"]})\n",
    "test_data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting results\n",
    "test_data_sub.to_csv('output/xgboost_pred_submission_v2.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
