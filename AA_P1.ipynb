{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f115f2a3-38a9-4391-b240-33e8d9069276",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Your model will be evaluated using two metrics: profit @ top-20, and AUC. The reasons for this is to be in line with a more realistic setting. E.g. one can image data scientists in a team arguing to use AUC and optimize for that. However, as seen in the course, for this scenario, we also imagine management arguing that there is not enough budget (in terms of time and money) to contact a lot of people (or hand out a lot of promotions). Hence, they have come up with the following: based on the top-k would-be churners as predicted by your model, sum some proxy of \"retained profitability\" in case the customer was indeed a churner, or zero otherwise\n",
    "\n",
    "As a proxy of profitability, the feature average cost min was deemed to be a good value. Based on the size of the test set, k=20 was deemed to be a good choice. Hence, management cares about optimizing this metric\n",
    "Note that only about half of the test set is used for the \"public\" leaderboard. That means that the score you will see on the leaderboard is done using this part of the test only (you don't know which half). Later on through the semester, submissions are frozen and the resuls on the \"hidden\" part will be revealed\n",
    "\n",
    "Also, whilst you can definitely try, the goal is not to \"win\", but to help you reflect on your model's results, see how others are doing, etc.\n",
    "\n",
    "Objectives:\n",
    "\n",
    "Some groups prefer to write their final report using Jupyter Notebook, which is fine too, as long as it is readable top-to-bottom\n",
    "\n",
    "You can use any predictive technique/approach you want, though focus on the whole process: general setup, critical thinking, and the ability to get and validate an outcome\n",
    "\n",
    "You're free to use unsupervised technique for your data exploration part, too. When you decide to build a black box model, including some interpretability techniques to explain it is a plus\n",
    "\n",
    "Any other assumptions or insights are thoughts can be included as well: the idea is to take what we've seen in class, get your hands dirty and try out what we've seen\n",
    "\n",
    "Perform a critical review of the evaluation metric chosen by management. How in line is it with AUC? What would you have picked instead? Were there particular issues with this chosen metric, in your view?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0f37fc-1746-44a5-aae7-235843420f05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0beaee9-7c53-4c08-9456-0908ae35e2c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd9425-b15a-4260-80d2-c4ba771f6b72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
